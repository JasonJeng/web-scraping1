{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WebScraping.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNU1cJmZ2WJtQS5ZMnIkuo6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JasonJeng/web-scraping1/blob/main/WebScraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5p8PN889zZht"
      },
      "source": [
        "# **Web Scraping in Python**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptQ57M8qKrQg"
      },
      "source": [
        "# Zexing Zheng\n",
        "# Python version: 3\n",
        "# 03/20/2021\n",
        "# This assignment contains two parts: tutorial and the Sony Wiki scraping. Alothough the homework only requires the \"own\" scraping section in one \n",
        "# coding block, I think it is good to do the tutorial and keep it in this assignment for future studiies."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POoE005jsTaV"
      },
      "source": [
        " **Web Scraping Tutorial**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EihBaMRpKjWe"
      },
      "source": [
        "# install libraries\n",
        "!pip install requests\n",
        "!pip install lxml\n",
        "!pip install bs4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-iI9TdUKsHE"
      },
      "source": [
        "# importing libraries\n",
        "import requests\n",
        "import bs4"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVY-f0zUUn-j"
      },
      "source": [
        "result = requests.get(\"http://example.com/\")\n",
        "# check type, which will show that you've successful sent your request.\n",
        "type(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3B_QgLKmUy-C"
      },
      "source": [
        "# Running the following will give us all the html for that page as a Python string\n",
        "result.text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVqhCoqtoHpM"
      },
      "source": [
        "# Parse your HTML using Beautiful Soup...\n",
        "soup = bs4.BeautifulSoup(result.text, \"lxml\") # arguments here include what we're parsing, and which engine we're using."
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiLWgvh5oMNL"
      },
      "source": [
        "# Calling the soup shows how our parser has nicely organized the html as a \"soup object\" so we can see the different page elements.\n",
        "soup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yAWpAQgoU2g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3603b0a1-32b4-4d81-b8c7-e63af71f9ecb"
      },
      "source": [
        "# Grab some raw HTML elements: by default this will return a list that includes the tags\n",
        "soup.select('title')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<title>Example Domain</title>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eXy-zpwoe-d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9819c069-6c8c-47a3-d803-f815d7dae9f1"
      },
      "source": [
        "# use the select method, specify the index - 0 since there's only one, then get text.\n",
        "soup.select('title')[0].getText()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Example Domain'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8cCFMVhrH-X"
      },
      "source": [
        " **Web Scraping From Sony Wiki Page**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCPtRCnps-J5",
        "outputId": "9622406a-6785-484f-8ac5-067bd74854a4"
      },
      "source": [
        "# importing libraries (In case I forget to run previous tutorial steps)\n",
        "import requests\n",
        "import bs4\n",
        "res = requests.get('https://en.wikipedia.org/wiki/Sony') # Make a request to the webpage\n",
        "sony_soup = bs4.BeautifulSoup(res.text, \"lxml\") # Phrase the HTML using Beautiful soup\n",
        "fifth_item = sony_soup.select('.toctext')[4] # I want to scrape \"Formats and technologies\" \n",
        "# or the fifth \"toctext\" class item from the website, so I specify the target by adding \"[4]\"\n",
        "print(fifth_item.text) # Make it into a text file, not HTML code. Using print to remove ''\n",
        "\n",
        "# OR using \"for\" loop to scrape all \"toctext\" items from the website!\n",
        "#for item in sony_soup.select('.toctext'):\n",
        "  #print(item.text) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Formats and technologies\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}